{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40bc2fc6",
   "metadata": {},
   "source": [
    "### We will be doing fake news prediction using Logistic Regression since the news is a binary classification problem the(either fake or real news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a3d3fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\monkey\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\monkey\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\monkey\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\monkey\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\monkey\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\monkey\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a113ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33d660a",
   "metadata": {},
   "source": [
    "##### re : regular expression. Useful for searching text data document\n",
    "##### NLTK = Natural Language Tool Kit\n",
    "##### TfidfVectorizer :converts text into feature vectors( i.e Text to numbers)\n",
    "Stopwords are words that do not add much value to the dataset(eg :The , This  etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ddf76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c59ae01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MoNkEy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "809e6858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dd71aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Fake News/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a92e7ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20795</th>\n",
       "      <td>20795</td>\n",
       "      <td>Rapper T.I.: Trump a ’Poster Child For White S...</td>\n",
       "      <td>Jerome Hudson</td>\n",
       "      <td>Rapper T. I. unloaded on black celebrities who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20796</th>\n",
       "      <td>20796</td>\n",
       "      <td>N.F.L. Playoffs: Schedule, Matchups and Odds -...</td>\n",
       "      <td>Benjamin Hoffman</td>\n",
       "      <td>When the Green Bay Packers lost to the Washing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20797</th>\n",
       "      <td>20797</td>\n",
       "      <td>Macy’s Is Said to Receive Takeover Approach by...</td>\n",
       "      <td>Michael J. de la Merced and Rachel Abrams</td>\n",
       "      <td>The Macy’s of today grew from the union of sev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20798</th>\n",
       "      <td>20798</td>\n",
       "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
       "      <td>Alex Ansary</td>\n",
       "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799</th>\n",
       "      <td>20799</td>\n",
       "      <td>What Keeps the F-35 Alive</td>\n",
       "      <td>David Swanson</td>\n",
       "      <td>David Swanson is an author, activist, journa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20800 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0          0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1          1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2          2                  Why the Truth Might Get You Fired   \n",
       "3          3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4          4  Iranian woman jailed for fictional unpublished...   \n",
       "...      ...                                                ...   \n",
       "20795  20795  Rapper T.I.: Trump a ’Poster Child For White S...   \n",
       "20796  20796  N.F.L. Playoffs: Schedule, Matchups and Odds -...   \n",
       "20797  20797  Macy’s Is Said to Receive Takeover Approach by...   \n",
       "20798  20798  NATO, Russia To Hold Parallel Exercises In Bal...   \n",
       "20799  20799                          What Keeps the F-35 Alive   \n",
       "\n",
       "                                          author  \\\n",
       "0                                  Darrell Lucus   \n",
       "1                                Daniel J. Flynn   \n",
       "2                             Consortiumnews.com   \n",
       "3                                Jessica Purkiss   \n",
       "4                                 Howard Portnoy   \n",
       "...                                          ...   \n",
       "20795                              Jerome Hudson   \n",
       "20796                           Benjamin Hoffman   \n",
       "20797  Michael J. de la Merced and Rachel Abrams   \n",
       "20798                                Alex Ansary   \n",
       "20799                              David Swanson   \n",
       "\n",
       "                                                    text  label  \n",
       "0      House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1      Ever get the feeling your life circles the rou...      0  \n",
       "2      Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3      Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4      Print \\nAn Iranian woman has been sentenced to...      1  \n",
       "...                                                  ...    ...  \n",
       "20795  Rapper T. I. unloaded on black celebrities who...      0  \n",
       "20796  When the Green Bay Packers lost to the Washing...      0  \n",
       "20797  The Macy’s of today grew from the union of sev...      0  \n",
       "20798  NATO, Russia To Hold Parallel Exercises In Bal...      1  \n",
       "20799    David Swanson is an author, activist, journa...      1  \n",
       "\n",
       "[20800 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86309afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      20800 non-null  int64 \n",
      " 1   title   20242 non-null  object\n",
      " 2   author  18843 non-null  object\n",
      " 3   text    20761 non-null  object\n",
      " 4   label   20800 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47cd5a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "797dfc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9977e",
   "metadata": {},
   "source": [
    "### Fill the missing values with null strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0125ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ba886d",
   "metadata": {},
   "source": [
    "I will use the author and title columns to make predictions. We can also use the text column but for simplicity I will combine the  title and author columns and use the resulting column instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd63214",
   "metadata": {},
   "source": [
    "Lets first merge the author and title columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a55190fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"content\"] = df[\"author\"]+\" \"+df[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db7c68e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Darrell Lucus House Dem Aide: We Didn’t Even S...\n",
       "1        Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...\n",
       "2        Consortiumnews.com Why the Truth Might Get You...\n",
       "3        Jessica Purkiss 15 Civilians Killed In Single ...\n",
       "4        Howard Portnoy Iranian woman jailed for fictio...\n",
       "                               ...                        \n",
       "20795    Jerome Hudson Rapper T.I.: Trump a ’Poster Chi...\n",
       "20796    Benjamin Hoffman N.F.L. Playoffs: Schedule, Ma...\n",
       "20797    Michael J. de la Merced and Rachel Abrams Macy...\n",
       "20798    Alex Ansary NATO, Russia To Hold Parallel Exer...\n",
       "20799              David Swanson What Keeps the F-35 Alive\n",
       "Name: content, Length: 20800, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0582977",
   "metadata": {},
   "source": [
    "#### We will then use the content column and the labels to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ee32e",
   "metadata": {},
   "source": [
    "## We then perform Stemming\n",
    "### Stemming is the process of reducing a word to its root word     \n",
    "\n",
    "Using: from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af2f596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5afa1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "    # removes everytrhing that is not an alphabet in the content column(^a-zA-Z means exclude characters that are not in the\n",
    "    # alphabet in both lower and upper case.).\n",
    "    stemmed_content = re.sub(\"[^a-zA-Z]\",\" \", content)\n",
    "    \n",
    "    # converts the case to lower case\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    \n",
    "    #splits and converts the characters into a list\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    \n",
    "    # we then perform stemming on the words in the list and removing the stopwords\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words(\"english\")]\n",
    "    \n",
    "    # we then join all the words after performing the above operations\n",
    "    stemmed_content = \" \".join(stemmed_content)\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ca8dd",
   "metadata": {},
   "source": [
    "## We then apply the function above to the content column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5af3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"content\"] = df[\"content\"].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34a51da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        darrel lucu hous dem aid even see comey letter...\n",
       "1        daniel j flynn flynn hillari clinton big woman...\n",
       "2                   consortiumnew com truth might get fire\n",
       "3        jessica purkiss civilian kill singl us airstri...\n",
       "4        howard portnoy iranian woman jail fiction unpu...\n",
       "                               ...                        \n",
       "20795    jerom hudson rapper trump poster child white s...\n",
       "20796    benjamin hoffman n f l playoff schedul matchup...\n",
       "20797    michael j de la merc rachel abram maci said re...\n",
       "20798    alex ansari nato russia hold parallel exercis ...\n",
       "20799                            david swanson keep f aliv\n",
       "Name: content, Length: 20800, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "071f6837",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"content\"].values\n",
    "y = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ccd57bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['darrel lucu hous dem aid even see comey letter jason chaffetz tweet',\n",
       "       'daniel j flynn flynn hillari clinton big woman campu breitbart',\n",
       "       'consortiumnew com truth might get fire', ...,\n",
       "       'michael j de la merc rachel abram maci said receiv takeov approach hudson bay new york time',\n",
       "       'alex ansari nato russia hold parallel exercis balkan',\n",
       "       'david swanson keep f aliv'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b63c152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e39c00",
   "metadata": {},
   "source": [
    "#### Using the TfidfVectorizer, we convert the content into feature vectors(i.e: numerical values) that can be used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f26d0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0bcada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "176f6bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15686)\t0.28485063562728646\n",
      "  (0, 13473)\t0.2565896679337957\n",
      "  (0, 8909)\t0.3635963806326075\n",
      "  (0, 8630)\t0.29212514087043684\n",
      "  (0, 7692)\t0.24785219520671603\n",
      "  (0, 7005)\t0.21874169089359144\n",
      "  (0, 4973)\t0.233316966909351\n",
      "  (0, 3792)\t0.2705332480845492\n",
      "  (0, 3600)\t0.3598939188262559\n",
      "  (0, 2959)\t0.2468450128533713\n",
      "  (0, 2483)\t0.3676519686797209\n",
      "  (0, 267)\t0.27010124977708766\n",
      "  (1, 16799)\t0.30071745655510157\n",
      "  (1, 6816)\t0.1904660198296849\n",
      "  (1, 5503)\t0.7143299355715573\n",
      "  (1, 3568)\t0.26373768806048464\n",
      "  (1, 2813)\t0.19094574062359204\n",
      "  (1, 2223)\t0.3827320386859759\n",
      "  (1, 1894)\t0.15521974226349364\n",
      "  (1, 1497)\t0.2939891562094648\n",
      "  (2, 15611)\t0.41544962664721613\n",
      "  (2, 9620)\t0.49351492943649944\n",
      "  (2, 5968)\t0.3474613386728292\n",
      "  (2, 5389)\t0.3866530551182615\n",
      "  (2, 3103)\t0.46097489583229645\n",
      "  :\t:\n",
      "  (20797, 13122)\t0.2482526352197606\n",
      "  (20797, 12344)\t0.27263457663336677\n",
      "  (20797, 12138)\t0.24778257724396507\n",
      "  (20797, 10306)\t0.08038079000566466\n",
      "  (20797, 9588)\t0.174553480255222\n",
      "  (20797, 9518)\t0.2954204003420313\n",
      "  (20797, 8988)\t0.36160868928090795\n",
      "  (20797, 8364)\t0.22322585870464118\n",
      "  (20797, 7042)\t0.21799048897828688\n",
      "  (20797, 3643)\t0.21155500613623743\n",
      "  (20797, 1287)\t0.33538056804139865\n",
      "  (20797, 699)\t0.30685846079762347\n",
      "  (20797, 43)\t0.29710241860700626\n",
      "  (20798, 13046)\t0.22363267488270608\n",
      "  (20798, 11052)\t0.4460515589182236\n",
      "  (20798, 10177)\t0.3192496370187028\n",
      "  (20798, 6889)\t0.32496285694299426\n",
      "  (20798, 5032)\t0.4083701450239529\n",
      "  (20798, 1125)\t0.4460515589182236\n",
      "  (20798, 588)\t0.3112141524638974\n",
      "  (20798, 350)\t0.28446937819072576\n",
      "  (20799, 14852)\t0.5677577267055112\n",
      "  (20799, 8036)\t0.45983893273780013\n",
      "  (20799, 3623)\t0.37927626273066584\n",
      "  (20799, 377)\t0.5677577267055112\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "821da03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b0889cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fd3865",
   "metadata": {},
   "source": [
    "### We then evaluate the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "456735a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on training data is:  98.65985576923076 %\n"
     ]
    }
   ],
   "source": [
    "X_train_pred = model.predict(X_train)\n",
    "train_data_accuracy = accuracy_score(X_train_pred, y_train)\n",
    "\n",
    "print(\"Accuracy score on training data is: \", train_data_accuracy *100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ad8e97",
   "metadata": {},
   "source": [
    "### We then evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6f93301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test data is:  97.90865384615385 %\n"
     ]
    }
   ],
   "source": [
    "X_test_pred = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_pred, y_test)\n",
    "\n",
    "print(\"Accuracy score on test data is: \", test_data_accuracy *100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee19ef4",
   "metadata": {},
   "source": [
    "### We then create a prediction system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "859af2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12801)\t0.2910746804557067\n",
      "  (0, 9818)\t0.30786004182651133\n",
      "  (0, 7668)\t0.22945314906455008\n",
      "  (0, 6816)\t0.16094563145945953\n",
      "  (0, 6289)\t0.288254092437116\n",
      "  (0, 5941)\t0.288254092437116\n",
      "  (0, 5233)\t0.21316265672448448\n",
      "  (0, 4346)\t0.3250084367199054\n",
      "  (0, 3395)\t0.3301936745912874\n",
      "  (0, 2959)\t0.24534646237198773\n",
      "  (0, 1667)\t0.30373060380734146\n",
      "  (0, 908)\t0.213510750423647\n",
      "  (0, 239)\t0.34297808354766485\n"
     ]
    }
   ],
   "source": [
    "# Taking the first row from the test dataset\n",
    "X_new = X_test[0]\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "86d2ef44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "News is Fake\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_new)\n",
    "print(prediction)\n",
    "\n",
    "if prediction == 0:\n",
    "    print(\"News is real\")\n",
    "else:\n",
    "    print(\"News is Fake\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
